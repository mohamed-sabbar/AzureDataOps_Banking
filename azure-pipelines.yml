trigger:
  branches:
    include:
      - main
  paths:
    include:
      - notebooks/**

pool:
  vmImage: 'ubuntu-latest'

variables:
  - group: variable group
  - name: DATABRICKS_HOST
    value: 'https://adb-1119135389290183.3.azuredatabricks.net'
  - name: DATABRICKS_WORKSPACE_PATH
    value: '/Workspace/Users/mohamedazrou2003@gmail.com'
  - name: DATABRICKS_JOB_ID
    value: '89'   # üëâ Mets l‚ÄôID r√©el de ton job Databricks

steps:
  # DEBUG: V√©rifier le contenu du repository
  - script: |
      echo "üìÇ STRUCTURE DU REPOSITORY:"
      ls -R
      echo ""
      echo "üìÅ Contenu du dossier notebooks:"
      ls -la notebooks/ || echo "‚ùå Le dossier notebooks n'existe pas!"
    displayName: 'üîç DEBUG - Structure du repo'
  
  # DEBUG: V√©rifier les changements
  - script: |
      echo "üîç COMMITS R√âCENTS:"
      git log --oneline -5
      echo ""
      echo "üìù FICHIERS MODIFI√âS DANS LE DERNIER COMMIT:"
      git diff --name-only HEAD~1 HEAD || git ls-files
      echo ""
      echo "üéØ FICHIERS NOTEBOOKS MODIFI√âS:"
      git diff --name-only HEAD~1 HEAD | grep "^notebooks/" || echo "Aucun notebook modifi√©"
    displayName: 'üîç DEBUG - Changements d√©tect√©s'
  
  # Installer Python
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.10'
    displayName: 'Installer Python 3.10'
  
  # Installer d√©pendances
  - script: |
      pip install -r requirements.txt
      pip install databricks-cli
    displayName: 'Installer d√©pendances'
  
  # Configuration Databricks CLI
  - script: |
      cat > ~/.databrickscfg <<EOF
      [DEFAULT]
      host = $(DATABRICKS_HOST)
      token = $(DATABRICKS_TOKEN)
      EOF
      
      databricks jobs configure --version=2.1
      echo "‚úÖ CLI Databricks configur√©e"
      
      # Tester la connexion
      echo ""
      echo "üîå TEST DE CONNEXION:"
      databricks workspace ls /Workspace/Users || echo "‚ùå Connexion √©chou√©e"
    displayName: 'Configurer Databricks CLI'
  
  # D√©ployer TOUS les notebooks (sans condition)
  - script: |
      echo "üì§ D√âPLOIEMENT DE TOUS LES NOTEBOOKS"
      echo "Source: $(Build.SourcesDirectory)/notebooks"
      echo "Destination: $(DATABRICKS_WORKSPACE_PATH)"
      echo ""
      
      if [ ! -d "notebooks" ]; then
        echo "‚ùå ERREUR: Le dossier 'notebooks' n'existe pas!"
        exit 1
      fi
      
      echo "üìù Fichiers √† d√©ployer:"
      find notebooks -type f
      echo ""
      
      databricks workspace import_dir notebooks $(DATABRICKS_WORKSPACE_PATH) --overwrite
      
      if [ $? -eq 0 ]; then
        echo "‚úÖ D√©ploiement r√©ussi!"
        echo "üìã NOTEBOOKS DANS DATABRICKS:"
        databricks workspace ls -l $(DATABRICKS_WORKSPACE_PATH)
      else
        echo "‚ùå √âchec du d√©ploiement"
        exit 1
      fi
    displayName: 'D√©ployer notebooks vers Databricks'

  # Comparer les contenus
  - script: |
      echo "üîÑ COMPARAISON DES CONTENUS"
      echo ""
      
      for notebook in notebooks/*.py notebooks/*.ipynb; do
        if [ -f "$notebook" ]; then
          filename=$(basename "$notebook")
          echo "üìÑ Fichier local: $filename"
          echo "Taille: $(wc -l < "$notebook") lignes"
          echo "Hash MD5: $(md5sum "$notebook" | cut -d' ' -f1)"
          
          echo "üì• T√©l√©chargement depuis Databricks..."
          databricks workspace export $(DATABRICKS_WORKSPACE_PATH)/$filename /tmp/$filename --format SOURCE 2>/dev/null
          
          if [ -f "/tmp/$filename" ]; then
            echo "Hash MD5 Databricks: $(md5sum /tmp/$filename | cut -d' ' -f1)"
            
            if diff "$notebook" "/tmp/$filename" > /dev/null; then
              echo "‚úÖ Les fichiers sont identiques"
            else
              echo "‚ö†Ô∏è LES FICHIERS SONT DIFFERENTS!"
              diff "$notebook" "/tmp/$filename" | head -20
            fi
          else
            echo "‚ö†Ô∏è Impossible de t√©l√©charger depuis Databricks"
          fi
          
          echo "---"
        fi
      done
    displayName: 'üîç V√©rifier synchronisation'

  ###########################################################
  # üöÄ EX√âCUTER LE JOB DATABRICKS APR√àS D√âPLOIEMENT
  ###########################################################
  - script: sudo apt-get install -y jq
    displayName: 'Installer jq (parser JSON)'

  - script: |
      echo "üöÄ Lancement du Job Databricks ID=$(DATABRICKS_JOB_ID)"
      
      run_id=$(databricks jobs run-now --job-id $(DATABRICKS_JOB_ID) | jq -r '.run_id')
      
      if [ -z "$run_id" ]; then
        echo "‚ùå ERREUR: Aucun run_id retourn√©!"
        exit 1
      fi
      
      echo "‚ñ∂Ô∏è Run ID lanc√© : $run_id"
      echo "‚è≥ En attente de la fin du job..."
      
      databricks runs wait --run-id $run_id
      
      echo "‚úÖ Job Databricks termin√© avec succ√®s!"
    displayName: 'üöÄ Ex√©cuter job Databricks apr√®s d√©ploiement'

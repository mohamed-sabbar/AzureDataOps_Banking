trigger:
  branches:
    include:
      - main
  paths:
    include:
      - notebooks/**

pool:
  vmImage: 'ubuntu-latest'

variables:
  - group: variable group
  - name: DATABRICKS_HOST
    value: 'https://adb-1119135389290183.3.azuredatabricks.net'
  - name: DATABRICKS_WORKSPACE_PATH
    value: '/Workspace/Users/mohamedazrou2003@gmail.com'
  - name: DATABRICKS_JOB_ID
    value: '811728064107146'

steps:
# 1ï¸âƒ£ DEBUG : Structure repo
- script: |
    echo "ğŸ“‚ STRUCTURE DU REPO :"
    ls -R
    echo "ğŸ“ Fichiers dans notebooks/"
    ls -la notebooks/ || echo "âŒ Le dossier notebooks n'existe pas"
  displayName: "ğŸ” DEBUG - Structure du repo"

# 2ï¸âƒ£ DEBUG : Fichiers modifiÃ©s
- script: |
    echo "ğŸ” COMMITS RÃ‰CENTS"
    git log --oneline -5 || echo "Pas d'historique git"
    echo "ğŸ“ FICHIERS MODIFIÃ‰S"
    git diff --name-only HEAD~1 HEAD 2>/dev/null || git ls-files
    echo "ğŸ¯ NOTEBOOKS MODIFIÃ‰S"
    git diff --name-only HEAD~1 HEAD 2>/dev/null | grep "^notebooks/" || echo "Aucun notebook modifiÃ©"
  displayName: "ğŸ” DEBUG - Changements dÃ©tectÃ©s"

# 3ï¸âƒ£ Installer Python
- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.10'
  displayName: "Installer Python 3.10"

# 4ï¸âƒ£ Installer dÃ©pendances
- script: |
    pip install databricks-cli
    if [ -f "requirements.txt" ]; then
      pip install -r requirements.txt
    else
      echo "â„¹ï¸ Aucun requirements.txt trouvÃ©"
    fi
  displayName: "Installer dÃ©pendances"

# 5ï¸âƒ£ Configurer Databricks CLI
- script: |
    mkdir -p ~/.databricks
    cat > ~/.databrickscfg <<EOF
    [DEFAULT]
    host = $(DATABRICKS_HOST)
    token = $(DATABRICKS_TOKEN)
    EOF
    echo "ğŸ”Œ Test CLI Databricks"
    databricks --version
    databricks workspace ls / || echo "âš ï¸ Erreur de connexion Databricks"
  displayName: "Configurer Databricks CLI"

# 6ï¸âƒ£ DÃ©ployer tous les notebooks vers Databricks
- script: |
    echo "ğŸ“¤ DÃ©ploiement des notebooks vers Databricks..."
    
    if [ ! -d "notebooks" ]; then
      echo "âŒ ERREUR : Le dossier notebooks n'existe pas"
      exit 1
    fi
    
    # VÃ©rifier qu'il y a des fichiers dans notebooks/
    if [ -z "$(ls -A notebooks/)" ]; then
      echo "âš ï¸ ATTENTION : Le dossier notebooks est vide"
      exit 1
    fi
    
    echo "ğŸ“‚ CrÃ©ation du rÃ©pertoire workspace si nÃ©cessaire..."
    databricks workspace mkdirs $(DATABRICKS_WORKSPACE_PATH) || echo "RÃ©pertoire dÃ©jÃ  existant"
    
    echo "ğŸ“¤ Import des notebooks..."
    databricks workspace import_dir notebooks $(DATABRICKS_WORKSPACE_PATH) --overwrite
    
    if [ $? -eq 0 ]; then
      echo "âœ… DÃ©ploiement rÃ©ussi !"
      echo "ğŸ“‹ Contenu du workspace :"
      databricks workspace ls -l $(DATABRICKS_WORKSPACE_PATH)
    else
      echo "âŒ ERREUR lors du dÃ©ploiement"
      exit 1
    fi
  displayName: "DÃ©ployer notebooks vers Databricks"

# 7ï¸âƒ£ VÃ©rifier synchro notebooks
- script: |
    echo "ğŸ”„ Comparaison des notebooks..."
    
    for notebook in notebooks/*.py notebooks/*.ipynb; do
      # VÃ©rifier si le fichier existe (Ã©viter l'erreur si aucun fichier ne correspond)
      if [ ! -f "$notebook" ]; then
        continue
      fi
      
      filename=$(basename "$notebook")
      echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      echo "ğŸ“„ Notebook local : $filename"
      echo "Hash local : $(md5sum "$notebook" | cut -d' ' -f1)"
      
      # Exporter depuis Databricks
      databricks workspace export "$(DATABRICKS_WORKSPACE_PATH)/$filename" "/tmp/$filename" --format SOURCE 2>/dev/null
      
      if [ -f "/tmp/$filename" ]; then
        echo "Hash Databricks : $(md5sum /tmp/$filename | cut -d' ' -f1)"
        
        if diff -q "$notebook" "/tmp/$filename" > /dev/null 2>&1; then
          echo "âœ”ï¸ Identique"
        else
          echo "âš ï¸ DiffÃ©rences dÃ©tectÃ©es"
          echo "DÃ©tails des diffÃ©rences :"
          diff "$notebook" "/tmp/$filename" | head -20
        fi
        rm -f "/tmp/$filename"
      else
        echo "âš ï¸ Impossible d'exporter depuis Databricks"
      fi
    done
  displayName: "ğŸ” VÃ©rifier synchronisation notebooks"
  continueOnError: true

# 8ï¸âƒ£ Installer jq
- script: |
    sudo apt-get update -qq
    sudo apt-get install -y jq
    jq --version
  displayName: "Installer jq"

# 9ï¸âƒ£ ExÃ©cuter le job Databricks
- script: |
    echo "ğŸš€ ExÃ©cution du job Databricks : $(DATABRICKS_JOB_ID)"
    
    # Lancer le job
    response=$(databricks jobs run-now --job-id $(DATABRICKS_JOB_ID) 2>&1)
    
    echo "ğŸ“¨ RÃ©ponse du lancement :"
    echo "$response"
    
    # Extraire le run_id
    run_id=$(echo "$response" | jq -r '.run_id // empty' 2>/dev/null)
    
    if [ -z "$run_id" ] || [ "$run_id" == "null" ]; then
      echo "âŒ ERREUR : Impossible de rÃ©cupÃ©rer le run_id"
      echo "RÃ©ponse brute : $response"
      exit 1
    fi
    
    echo "â–¶ï¸ Run ID : $run_id"
    echo "ğŸ”— Lien : $(DATABRICKS_HOST)/#job/$(DATABRICKS_JOB_ID)/run/$run_id"
    
    echo "â³ Attente de la fin du job..."
    
    # Attendre la fin du job avec timeout
    timeout 1800 databricks runs wait --run-id $run_id
    wait_exit_code=$?
    
    if [ $wait_exit_code -eq 0 ]; then
      echo "âœ… Job terminÃ© avec succÃ¨s !"
      
      # RÃ©cupÃ©rer le statut final
      run_status=$(databricks runs get --run-id $run_id | jq -r '.state.life_cycle_state')
      result_state=$(databricks runs get --run-id $run_id | jq -r '.state.result_state')
      
      echo "ğŸ“Š Ã‰tat final : $run_status"
      echo "ğŸ“Š RÃ©sultat : $result_state"
      
      if [ "$result_state" != "SUCCESS" ]; then
        echo "âŒ Le job s'est terminÃ© avec des erreurs : $result_state"
        exit 1
      fi
    elif [ $wait_exit_code -eq 124 ]; then
      echo "â±ï¸ TIMEOUT : Le job a dÃ©passÃ© 30 minutes"
      exit 1
    else
      echo "âŒ Erreur lors de l'attente du job"
      exit 1
    fi
  displayName: "ğŸš€ ExÃ©cuter job Databricks"
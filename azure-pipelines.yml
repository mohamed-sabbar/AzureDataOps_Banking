trigger:
  branches:
    include:
      - main
  paths:
    include:
      - notebooks/**

pool:
  vmImage: 'ubuntu-latest'

variables:
  - group: variable group
  - name: DATABRICKS_HOST
    value: 'https://adb-1119135389290183.3.azuredatabricks.net'
  - name: DATABRICKS_WORKSPACE_PATH
    value: '/Workspace/Users/mohamedazrou2003@gmail.com'

steps:
  # Installer Python
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.10'
    displayName: 'Installer Python 3.10'
  
  # Installer dÃ©pendances
  - script: |
      pip install -r requirements.txt
      pip install databricks-cli
    displayName: 'Installer dÃ©pendances'
  
  # Configuration Databricks CLI
  - script: |
      cat > ~/.databrickscfg <<EOF
      [DEFAULT]
      host = $(DATABRICKS_HOST)
      token = $(DATABRICKS_TOKEN)
      EOF
      
      databricks jobs configure --version=2.1
      echo "âœ… CLI Databricks configurÃ©e"
    displayName: 'Configurer Databricks CLI'
  
  # DÃ©tecter et dÃ©ployer les notebooks modifiÃ©s
  - script: |
      echo "ðŸ” DÃ©tection des notebooks modifiÃ©s..."
      
      # Obtenir les fichiers modifiÃ©s dans le dossier notebooks
      CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD | grep "^notebooks/" || true)
      
      if [ -z "$CHANGED_FILES" ]; then
        echo "âš ï¸ Aucun notebook modifiÃ©"
        echo "##vso[task.setvariable variable=HAS_CHANGES]false"
        exit 0
      fi
      
      echo "ðŸ“ Notebooks modifiÃ©s:"
      echo "$CHANGED_FILES"
      echo "##vso[task.setvariable variable=HAS_CHANGES]true"
      
      # DÃ©ployer tous les notebooks (pour s'assurer de la cohÃ©rence)
      echo ""
      echo "ðŸ“¤ DÃ©ploiement de tous les notebooks..."
      databricks workspace import_dir notebooks $(DATABRICKS_WORKSPACE_PATH) --overwrite
      
      if [ $? -eq 0 ]; then
        echo "âœ… Notebooks dÃ©ployÃ©s avec succÃ¨s"
      else
        echo "âŒ Erreur lors du dÃ©ploiement"
        exit 1
      fi
      
      # Lister les notebooks dÃ©ployÃ©s
      echo ""
      echo "ðŸ“‹ Notebooks disponibles dans Databricks:"
      databricks workspace ls $(DATABRICKS_WORKSPACE_PATH)
      
    displayName: 'DÃ©ployer notebooks modifiÃ©s'
  
  # ExÃ©cuter les notebooks modifiÃ©s
  - script: |
      if [ "$(HAS_CHANGES)" = "false" ]; then
        echo "â­ï¸ Aucun changement, skip de l'exÃ©cution"
        exit 0
      fi
      
      cat > execute_notebooks.py <<'PYTHON_SCRIPT'
      import os
      import sys
      import time
      import json
      from databricks_cli.sdk.api_client import ApiClient
      from databricks_cli.jobs.api import JobsApi
      from databricks_cli.runs.api import RunsApi
      
      # Configuration
      host = os.environ['DATABRICKS_HOST']
      token = os.environ['DATABRICKS_TOKEN']
      workspace_path = os.environ['DATABRICKS_WORKSPACE_PATH']
      
      # CrÃ©er le client API
      api_client = ApiClient(host=host, token=token)
      runs_api = RunsApi(api_client)
      
      # Liste des notebooks Ã  exÃ©cuter (dans l'ordre)
      notebooks = [
          "notebook1.py",  # Remplace par tes vrais noms
          "notebook2.py",
          "notebook3.py"
      ]
      
      def run_notebook(notebook_path):
          """ExÃ©cute un notebook et attend la fin"""
          print(f"\nðŸš€ ExÃ©cution du notebook: {notebook_path}")
          
          try:
              # ParamÃ¨tres d'exÃ©cution
              run_params = {
                  "notebook_task": {
                      "notebook_path": f"{workspace_path}/{notebook_path}",
                      "base_parameters": {}
                  },
                  "new_cluster": {
                      "spark_version": "13.3.x-scala2.12",
                      "node_type_id": "Standard_DS3_v2",
                      "num_workers": 1
                  }
              }
              
              # Lancer l'exÃ©cution
              response = runs_api.submit_run(**run_params)
              run_id = response['run_id']
              
              print(f"âœ… ExÃ©cution lancÃ©e - Run ID: {run_id}")
              print(f"ðŸ”— Lien: {host}/#job/0/run/{run_id}")
              
              # Attendre la fin
              print("â³ Attente de la fin de l'exÃ©cution...")
              
              while True:
                  run_info = runs_api.get_run(run_id)
                  state = run_info['state']['life_cycle_state']
                  
                  if state in ['TERMINATED', 'SKIPPED', 'INTERNAL_ERROR']:
                      result_state = run_info['state'].get('result_state', 'UNKNOWN')
                      
                      if result_state == 'SUCCESS':
                          print(f"âœ… {notebook_path} exÃ©cutÃ© avec succÃ¨s")
                          return True
                      else:
                          print(f"âŒ {notebook_path} Ã©chouÃ©: {result_state}")
                          if 'state_message' in run_info['state']:
                              print(f"Message: {run_info['state']['state_message']}")
                          return False
                  
                  time.sleep(15)
                  
          except Exception as e:
              print(f"âŒ Erreur lors de l'exÃ©cution de {notebook_path}: {str(e)}")
              return False
      
      # ExÃ©cuter tous les notebooks
      print("=" * 80)
      print("ðŸŽ¯ EXÃ‰CUTION DES NOTEBOOKS")
      print("=" * 80)
      
      all_success = True
      for notebook in notebooks:
          success = run_notebook(notebook)
          if not success:
              all_success = False
              print(f"\nâš ï¸ ArrÃªt suite Ã  l'Ã©chec de {notebook}")
              break
      
      print("\n" + "=" * 80)
      if all_success:
          print("âœ… TOUS LES NOTEBOOKS ONT Ã‰TÃ‰ EXÃ‰CUTÃ‰S AVEC SUCCÃˆS")
          print("=" * 80)
          sys.exit(0)
      else:
          print("âŒ Ã‰CHEC DE L'EXÃ‰CUTION DES NOTEBOOKS")
          print("=" * 80)
          sys.exit(1)
      PYTHON_SCRIPT
      
      python execute_notebooks.py
      
    displayName: 'ExÃ©cuter notebooks'
    env:
      DATABRICKS_HOST: $(DATABRICKS_HOST)
      DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)
      DATABRICKS_WORKSPACE_PATH: $(DATABRICKS_WORKSPACE_PATH)
    condition: eq(variables['HAS_CHANGES'], 'true')
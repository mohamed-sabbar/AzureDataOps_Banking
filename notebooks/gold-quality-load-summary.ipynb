{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a56ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count\n",
    "from datetime import datetime\n",
    "\n",
    "date_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Configuration\n",
    "storage_account = \"datalakemedallion\"\n",
    "dbutils.widgets.text(\"AZURE_STORAGE_KEY\", \"\")\n",
    "storage_key = dbutils.widgets.get(\"AZURE_STORAGE_KEY\")\n",
    "container_source_name = \"silver\"\n",
    "container_destinataire_name = \"gold\"\n",
    "folder_source = \"control_qualite\"\n",
    "folder_dv = \"data_valid\"\n",
    "folder_dinv = \"invalid_data\"\n",
    "\n",
    "# Configuration Spark et destination\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account}.blob.core.windows.net\", storage_key)\n",
    "spark.conf.set(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\", \"false\")\n",
    "spark.conf.set(\"parquet.enable.summary-metadata\", \"false\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint\", \"\")\n",
    "\n",
    "# Lecture des données\n",
    "## Lecture des données de comptes et clients\n",
    "df_clients = spark.read.parquet(f\"wasbs://{container_source_name}@{storage_account}.blob.core.windows.net/transformations/clients_trsf/\")\n",
    "df_comptes = spark.read.parquet(f\"wasbs://{container_source_name}@{storage_account}.blob.core.windows.net/transformations/comptes_trsf/\")\n",
    "\n",
    "## Lecture des données de transactions\n",
    "df_transactions_valid = spark.read.parquet(f\"wasbs://{container_source_name}@{storage_account}.blob.core.windows.net/control_qualite/valid_data/\")\n",
    "df_transactions_invalid= spark.read.parquet(f\"wasbs://{container_source_name}@{storage_account}.blob.core.windows.net/control_qualite/invalid_data/\")\n",
    "\n",
    "## Lire les données de tx brutes\n",
    "df_raw_tx = spark.read.parquet(f\"wasbs://bronze@{storage_account}.blob.core.windows.net/transactions/\")\n",
    "\n",
    "# Calcul des données\n",
    "total_raw_tx = df_raw_tx.count()\n",
    "valid = df_transactions_valid.count()\n",
    "invalid = df_transactions_invalid.count()\n",
    "total = valid + invalid\n",
    "nb_doublons = total_raw_tx - total\n",
    "taux_validite = round((invalid / total) * 100, 2)\n",
    "anomaly_counts = (df_transactions_invalid.groupBy(\"anomaly_type\").agg(count(\"*\").alias(\"count\")).collect())\n",
    "anomaly_dict = {row[\"anomaly_type\"]: row[\"count\"] for row in anomaly_counts}\n",
    "\n",
    "\n",
    "# construction du summary DF\n",
    "data_summary = [\n",
    "    (\n",
    "        total_raw_tx,\n",
    "        total,\n",
    "        valid,\n",
    "        invalid,\n",
    "        taux_validite,\n",
    "        nb_doublons,\n",
    "        anomaly_dict.get(\"Date future invalide\", 0),\n",
    "        anomaly_dict.get(\"Montant négatif ou nul\", 0),\n",
    "        anomaly_dict.get(\"Devise invalide\", 0),\n",
    "        anomaly_dict.get(\"Statut inconnu\", 0),\n",
    "        anomaly_dict.get(\"Compte inconnu\", 0),\n",
    "        anomaly_dict.get(\"Transaction ID inconnu\", 0),\n",
    "        anomaly_dict.get(\"Type de transaction inconnu\", 0),\n",
    "        anomaly_dict.get(\"Canal inconnu\", 0),\n",
    "        anomaly_dict.get(\"Catégorie commerçant inconnue\", 0),\n",
    "        anomaly_dict.get(\"Autre anomalie\", 0)\n",
    "    )\n",
    "]\n",
    "\n",
    "columns = [\n",
    "    \"total_transactions_avant_transformations\",\n",
    "    \"total_transactions_apres_transformations\",\n",
    "    \"valid_transactions\",\n",
    "    \"invalid_transactions\",\n",
    "    \"taux_validite\",\n",
    "    \"nb_doublons\",\n",
    "    \"nb_date_future\",\n",
    "    \"nb_montant_negatif\",\n",
    "    \"nb_devise_invalide\",\n",
    "    \"nb_statut_inconnu\",\n",
    "    \"nb_account_inconnu\",\n",
    "    \"nb_transaction_id_inconnu\",\n",
    "    \"nb_transaction_type_inconnu\",\n",
    "    \"nb_channel_inconnu\",\n",
    "    \"nb_merchant_category_inconnue\",\n",
    "    \"nb_autre_anomalie\"\n",
    "]\n",
    "\n",
    "df_summary = spark.createDataFrame(data_summary, columns)\n",
    "\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\", storage_key)\n",
    "spark.conf.set(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\", \"false\")\n",
    "spark.conf.set(\"parquet.enable.summary-metadata\", \"false\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint\", \"\")\n",
    "spark.conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\", \"1\") \n",
    "\n",
    "# chargement des données\n",
    "df_summary.coalesce(1).write.option(\"compression\",\"uncompressed\").mode(\"overwrite\").parquet(f\"abfss://{container_destinataire_name}@{storage_account}.dfs.core.windows.net/gold-summary/\")\n",
    "df_clients.coalesce(1).write.option(\"compression\",\"uncompressed\").mode(\"overwrite\").parquet(f\"abfss://{container_destinataire_name}@{storage_account}.dfs.core.windows.net/gold-clients/\")\n",
    "df_comptes.coalesce(1).write.option(\"compression\",\"uncompressed\").mode(\"overwrite\").parquet(f\"abfss://{container_destinataire_name}@{storage_account}.dfs.core.windows.net/gold-comptes/\")\n",
    "df_transactions_valid.coalesce(1).write.option(\"compression\",\"uncompressed\").mode(\"overwrite\").parquet(f\"abfss://{container_destinataire_name}@{storage_account}.dfs.core.windows.net/gold-transactions/valid-tx/\")\n",
    "df_transactions_invalid.coalesce(1).write.option(\"compression\",\"uncompressed\").mode(\"overwrite\").parquet(f\"abfss://{container_destinataire_name}@{storage_account}.dfs.core.windows.net/gold-transactions/invalid-tx/\")\n",
    "\n",
    "print(\"---- processus terminé ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e6764",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
